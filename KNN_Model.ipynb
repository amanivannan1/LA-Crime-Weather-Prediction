{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Read the  dataset from the following random_sampled_data.csv Links to an external site. and assign it to a Pandas DataFrame as you learned in tutorial Lab2-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DR_NO               Date Rptd                DATE OCC  TIME OCC  \\\n",
      "0    200104875  01/12/2020 12:00:00 AM  01/12/2020 12:00:00 AM      1955   \n",
      "1    200816285  11/11/2020 12:00:00 AM  11/10/2020 12:00:00 AM      1700   \n",
      "2    200304982  01/17/2020 12:00:00 AM  01/17/2020 12:00:00 AM      1825   \n",
      "3    200504796  01/19/2020 12:00:00 AM  01/19/2020 12:00:00 AM      1800   \n",
      "4    200316294  08/25/2020 12:00:00 AM  08/25/2020 12:00:00 AM       700   \n",
      "..         ...                     ...                     ...       ...   \n",
      "994  230616403  10/12/2023 12:00:00 AM  10/11/2023 12:00:00 AM      1420   \n",
      "995  231407108  03/16/2023 12:00:00 AM  03/15/2023 12:00:00 AM      2200   \n",
      "996  231815151  08/18/2023 12:00:00 AM  08/17/2023 12:00:00 AM      2300   \n",
      "997  230509664  06/07/2023 12:00:00 AM  06/07/2023 12:00:00 AM      1400   \n",
      "998  231404405  01/12/2023 12:00:00 AM  01/12/2023 12:00:00 AM      2235   \n",
      "\n",
      "     AREA  AREA NAME  Rpt Dist No  Part 1-2  Crm Cd  \\\n",
      "0       1    Central          171         2     888   \n",
      "1       8    West LA          897         1     310   \n",
      "2       3  Southwest          321         1     343   \n",
      "3       5     Harbor          528         1     210   \n",
      "4       3  Southwest          356         1     331   \n",
      "..    ...        ...          ...       ...     ...   \n",
      "994     6  Hollywood          615         1     331   \n",
      "995    14    Pacific         1468         2     626   \n",
      "996    18  Southeast         1822         1     420   \n",
      "997     5     Harbor          589         1     330   \n",
      "998    14    Pacific         1414         1     220   \n",
      "\n",
      "                                           Crm Cd Desc  ... Status  \\\n",
      "0                                          TRESPASSING  ...     IC   \n",
      "1                                             BURGLARY  ...     IC   \n",
      "2             SHOPLIFTING-GRAND THEFT ($950.01 & OVER)  ...     AA   \n",
      "3                                              ROBBERY  ...     IC   \n",
      "4    THEFT FROM MOTOR VEHICLE - GRAND ($950.01 AND ...  ...     IC   \n",
      "..                                                 ...  ...    ...   \n",
      "994  THEFT FROM MOTOR VEHICLE - GRAND ($950.01 AND ...  ...     IC   \n",
      "995                  INTIMATE PARTNER - SIMPLE ASSAULT  ...     AA   \n",
      "996    THEFT FROM MOTOR VEHICLE - PETTY ($950 & UNDER)  ...     IC   \n",
      "997                              BURGLARY FROM VEHICLE  ...     IC   \n",
      "998                                  ATTEMPTED ROBBERY  ...     AO   \n",
      "\n",
      "      Status Desc Crm Cd 1 Crm Cd 2  Crm Cd 3 Crm Cd 4  \\\n",
      "0     Invest Cont      888      NaN       NaN      NaN   \n",
      "1     Invest Cont      310    998.0       NaN      NaN   \n",
      "2    Adult Arrest      343      NaN       NaN      NaN   \n",
      "3     Invest Cont      210      NaN       NaN      NaN   \n",
      "4     Invest Cont      331      NaN       NaN      NaN   \n",
      "..            ...      ...      ...       ...      ...   \n",
      "994   Invest Cont      331      NaN       NaN      NaN   \n",
      "995  Adult Arrest      626      NaN       NaN      NaN   \n",
      "996   Invest Cont      420    998.0       NaN      NaN   \n",
      "997   Invest Cont      330      NaN       NaN      NaN   \n",
      "998   Adult Other      220    761.0       NaN      NaN   \n",
      "\n",
      "                                     LOCATION Cross Street      LAT       LON  \n",
      "0     1000 S  FIGUEROA                     ST          NaN  34.0457 -118.2665  \n",
      "1     3300 S  BEVERLY                      DR          NaN  34.0310 -118.3989  \n",
      "2     3500 S  LA CIENEGA                   BL          NaN  34.0242 -118.3722  \n",
      "3     1300 E  OPP                          ST          NaN  33.7875 -118.2479  \n",
      "4     1600 W  36TH                         ST          NaN  34.0228 -118.3069  \n",
      "..                                        ...          ...      ...       ...  \n",
      "994   2700    LAKE HOLLYWOOD               DR          NaN  34.1287 -118.3291  \n",
      "995  11900    ALLIN                        ST          NaN  33.9919 -118.4119  \n",
      "996                                      WALL        102ND  33.9438 -118.2717  \n",
      "997   3700    STEPHEN M WHITE              DR          NaN  33.7108 -118.2862  \n",
      "998    600    SANTA CLARA                  AV          NaN  33.9924 -118.4665  \n",
      "\n",
      "[999 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# The following line will import KNeighborsClassifier \"Class\"\n",
    "# KNeighborsClassifier is name of a \"sklearn class\" to perform \"KNN Classification\" \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "# reading a CSV file directly from Web, and store it in a pandas DataFrame:\n",
    "# \"read_csv\" is a pandas function to read csv files from web or local device:\n",
    "\n",
    "#Random 1000 samples and save the csv file\n",
    "# Set the total number of rows in the CSV file\n",
    "#total_rows = 852950  # You should replace this with the actual total number of rows in your dataset\n",
    "# Number of rows you want to read\n",
    "#num_rows = 1000\n",
    "# Include the first row and randomly sample the remaining rows\n",
    "#random_rows = [0] + random.sample(range(1, total_rows), num_rows - 1)\n",
    "# Read the CSV file for the specified random rows\n",
    "#df = pd.read_csv('../Final project/Crime_Data_from_2020_to_Present.csv', skiprows=lambda x: x not in random_rows)\n",
    "#df.to_csv(\"random_sampled_data.csv\", index=False)\n",
    "\n",
    "df = pd.read_csv(\"random_sampled_data.csv\")\n",
    "\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "\n",
    "# Print the DataFrame\n",
    "\n",
    "\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### B. Drop the fallowing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATE OCC\n",
      "AREA\n",
      "Crm Cd\n",
      "Crm Cd Desc\n",
      "Vict Age\n",
      "Vict Sex\n",
      "Vict Descent\n"
     ]
    }
   ],
   "source": [
    "new_x = df\n",
    "\n",
    "Drop_columns = [\n",
    "    'DR_NO',\n",
    "    'TIME OCC',\n",
    "    'Rpt Dist No',\n",
    "    'Part 1-2',\n",
    "    'LOCATION',\n",
    "    'AREA NAME',\n",
    "    'Weapon Used Cd',\n",
    "    'Premis Desc',\n",
    "    'Status Desc',\n",
    "    'Crm Cd 1',\n",
    "    'Crm Cd 2',\n",
    "    'Crm Cd 3',\n",
    "    'Crm Cd 4',\n",
    "    'Cross Street',\n",
    "    'Date Rptd',\n",
    "    'Mocodes',\n",
    "    'Weapon Desc',\n",
    "    'Status',\n",
    "    'Premis Cd',\n",
    "    'LAT',\n",
    "    'LON'\n",
    "    ]\n",
    "\n",
    "new_x = new_x.drop(columns=Drop_columns)\n",
    "\n",
    "for col in new_x.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### C. Now, we want to use the categorical features as well! To this end, we have to perform a feature engineering process called OneHotEncoding for the categorical features. To do this, each categorical feature should be replaced with dummy columns in the feature table (one column for each possible value of a categorical feature), and then encode it in a binary manner such that only one of the dummy columns can take “1” at a time (and zero for the rest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crm Cd Desc_ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT\n",
      "Crm Cd Desc_BURGLARY FROM VEHICLE\n",
      "Crm Cd Desc_CRIMINAL THREATS - NO WEAPON DISPLAYED\n",
      "AREA_11\n",
      "Vict Age\n",
      "AREA_10\n",
      "Crm Cd Desc_BRANDISH WEAPON\n",
      "Crm Cd Desc_THEFT FROM MOTOR VEHICLE - GRAND ($950.01 AND OVER)\n",
      "Fall\n",
      "Crm Cd Desc_DOCUMENT FORGERY / STOLEN FELONY\n",
      "AREA_21\n",
      "Day_of_week_25\n",
      "Day_of_week_28\n",
      "Crm Cd Desc_INTIMATE PARTNER - SIMPLE ASSAULT\n",
      "Day_of_week_18\n",
      "Crm Cd Desc_INTIMATE PARTNER - AGGRAVATED ASSAULT\n",
      "Crm Cd_110\n",
      "Crm Cd_814\n",
      "AREA_17\n",
      "Crm Cd_666\n",
      "Vict Descent_A\n",
      "Day_of_week_30\n",
      "Crm Cd_434\n",
      "Crm Cd_810\n",
      "Day_of_week_3\n",
      "Crm Cd Desc_RAPE, ATTEMPTED\n",
      "Crm Cd Desc_ORAL COPULATION\n",
      "Crm Cd_230\n",
      "AREA_6\n",
      "Crm Cd_762\n",
      "AREA_5\n",
      "AREA_14\n",
      "AREA_4\n",
      "Day_of_week_22\n",
      "Crm Cd Desc_CHILD ABUSE (PHYSICAL) - SIMPLE ASSAULT\n",
      "Crm Cd Desc_CHILD NEGLECT (SEE 300 W.I.C.)\n",
      "Crm Cd Desc_ATTEMPTED ROBBERY\n",
      "Day_of_week_10\n",
      "Vict Descent_O\n",
      "Crm Cd_930\n",
      "Crm Cd Desc_VEHICLE - ATTEMPT STOLEN\n",
      "AREA_19\n",
      "Crm Cd_480\n",
      "Crm Cd Desc_DISTURBING THE PEACE\n",
      "Crm Cd_341\n",
      "Crm Cd Desc_LETTERS, LEWD  -  TELEPHONE CALLS, LEWD\n",
      "Crm Cd Desc_CONTEMPT OF COURT\n",
      "Crm Cd_815\n",
      "Crm Cd_662\n",
      "Crm Cd_236\n",
      "Crm Cd_440\n",
      "Crm Cd_649\n",
      "Day_of_week_9\n",
      "Winter\n",
      "Crm Cd_420\n",
      "Vict Descent_L\n",
      "Vict Descent_K\n",
      "Crm Cd_331\n",
      "Day_of_week_17\n",
      "Day_of_week_24\n",
      "Crm Cd_210\n",
      "Crm Cd_251\n",
      "Crm Cd Desc_CHILD PORNOGRAPHY\n",
      "Crm Cd_121\n",
      "Day_of_week_29\n",
      "Crm Cd_648\n",
      "Day_of_week_27\n",
      "Crm Cd Desc_LEWD CONDUCT\n",
      "Crm Cd Desc_SHOTS FIRED AT INHABITED DWELLING\n",
      "Crm Cd Desc_THEFT FROM MOTOR VEHICLE - PETTY ($950 & UNDER)\n",
      "Crm Cd Desc_FALSE IMPRISONMENT\n",
      "AREA_13\n",
      "Crm Cd_237\n",
      "Crm Cd_901\n",
      "Crm Cd Desc_SODOMY/SEXUAL CONTACT B/W PENIS OF ONE PERS TO ANUS OTH\n",
      "Day_of_week_12\n",
      "Crm Cd Desc_BIKE - STOLEN\n",
      "Crm Cd Desc_THEFT PLAIN - ATTEMPT\n",
      "Day_of_week_23\n",
      "Crm Cd Desc_PICKPOCKET\n",
      "Crm Cd Desc_TRESPASSING\n",
      "Vict Descent_J\n",
      "Crm Cd Desc_BUNCO, PETTY THEFT\n",
      "AREA_8\n",
      "Crm Cd_350\n",
      "Crm Cd Desc_EXTORTION\n",
      "Crm Cd_520\n",
      "Crm Cd_813\n",
      "Crm Cd_647\n",
      "Crm Cd_860\n",
      "Crm Cd Desc_THEFT-GRAND ($950.01 & OVER)EXCPT,GUNS,FOWL,LIVESTK,PROD\n",
      "Crm Cd Desc_OTHER ASSAULT\n",
      "Crm Cd Desc_RAPE, FORCIBLE\n",
      "Day_of_week_6\n",
      "Crm Cd Desc_BURGLARY, ATTEMPTED\n",
      "Day_of_week_31\n",
      "Crm Cd Desc_CHILD ANNOYING (17YRS & UNDER)\n",
      "Day_of_week_16\n",
      "Vict Descent_C\n",
      "Day_of_week_8\n",
      "Crm Cd_441\n",
      "Crm Cd_442\n",
      "Day_of_week_5\n",
      "Day_of_week_7\n",
      "AREA_18\n",
      "Day_of_week_21\n",
      "AREA_12\n",
      "Vict Descent_B\n",
      "Day_of_week_2\n",
      "Crm Cd_821\n",
      "Crm Cd Desc_VIOLATION OF RESTRAINING ORDER\n",
      "Crm Cd_946\n",
      "Crm Cd_956\n",
      "AREA_1\n",
      "Crm Cd_668\n",
      "Crm Cd_122\n",
      "Crm Cd Desc_ROBBERY\n",
      "Crm Cd_761\n",
      "Crm Cd Desc_BUNCO, GRAND THEFT\n",
      "Crm Cd Desc_BURGLARY\n",
      "Crm Cd_745\n",
      "Crm Cd Desc_VANDALISM - FELONY ($400 & OVER, ALL CHURCH VANDALISMS)\n",
      "Day_of_week_11\n",
      "Crm Cd Desc_BATTERY - SIMPLE ASSAULT\n",
      "Crm Cd_627\n",
      "Day_of_week_15\n",
      "Vict Descent_H\n",
      "Day_of_week_26\n",
      "Crm Cd Desc_BUNCO, ATTEMPT\n",
      "Day_of_week_20\n",
      "Crm Cd_812\n",
      "Crm Cd_352\n",
      "AREA_15\n",
      "Crm Cd_320\n",
      "AREA_2\n",
      "Crm Cd Desc_SEXUAL PENETRATION W/FOREIGN OBJECT\n",
      "Crm Cd Desc_THEFT, PERSON\n",
      "Day_of_week_14\n",
      "AREA_9\n",
      "Spring\n",
      "Crm Cd_760\n",
      "AREA_20\n",
      "Crm Cd_888\n",
      "Crm Cd Desc_VIOLATION OF COURT ORDER\n",
      "Day_of_week_13\n",
      "Day_of_week_19\n",
      "Summer\n",
      "Crm Cd_664\n",
      "Crm Cd_850\n",
      "Crm Cd_900\n",
      "Crm Cd_310\n",
      "Day_of_week_4\n",
      "Vict Descent_F\n",
      "Crm Cd_740\n",
      "Crm Cd_624\n",
      "Vict Descent_W\n",
      "Crm Cd Desc_INDECENT EXPOSURE\n",
      "Crm Cd Desc_SEX,UNLAWFUL(INC MUTUAL CONSENT, PENETRATION W/ FRGN OBJ\n",
      "Crm Cd_820\n",
      "Crm Cd Desc_THROWING OBJECT AT MOVING VEHICLE\n",
      "Crm Cd_354\n",
      "Crm Cd Desc_SHOPLIFTING - PETTY THEFT ($950 & UNDER)\n",
      "Crm Cd Desc_THEFT PLAIN - PETTY ($950 & UNDER)\n",
      "Crm Cd Desc_LEWD/LASCIVIOUS ACTS WITH CHILD\n",
      "Crm Cd Desc_VANDALISM - MISDEAMEANOR ($399 OR UNDER)\n",
      "Crm Cd_903\n",
      "AREA_7\n",
      "AREA_16\n",
      "Crm Cd Desc_OTHER MISCELLANEOUS CRIME\n",
      "Crm Cd_626\n",
      "Crm Cd Desc_EMBEZZLEMENT, GRAND THEFT ($950.01 & OVER)\n",
      "Crm Cd Desc_THEFT OF IDENTITY\n",
      "Crm Cd Desc_ARSON\n",
      "Crm Cd_330\n",
      "Crm Cd_940\n",
      "Crm Cd_886\n",
      "Crm Cd Desc_CRM AGNST CHLD (13 OR UNDER) (14-15 & SUSP 10 YRS OLDER)\n",
      "Crm Cd_220\n",
      "Crm Cd Desc_CRIMINAL HOMICIDE\n",
      "Crm Cd_625\n",
      "Crm Cd Desc_BATTERY WITH SEXUAL CONTACT\n",
      "AREA_3\n",
      "Day_of_week_1\n"
     ]
    }
   ],
   "source": [
    "# Creating the Feature Matrix for dataset:\n",
    "\n",
    "\n",
    "\n",
    "# Function to map month to season\n",
    "def get_season(month):\n",
    "    if 3 <= month <= 5:\n",
    "        return 'Spring'\n",
    "    elif 6 <= month <= 8:\n",
    "        return 'Summer'\n",
    "    elif 9 <= month <= 11:\n",
    "        return 'Fall'\n",
    "    else:\n",
    "        return 'Winter'\n",
    "\n",
    "\n",
    "# Extracting the month from the 'Date' column and mapping it to seasons\n",
    "#new_x['Month'] = pd.to_datetime(new_x['date_occ']).dt.month\n",
    "\n",
    "new_x['Month'] = pd.to_datetime(new_x['DATE OCC']).dt.month\n",
    "new_x['Day_of_week'] = pd.to_datetime(new_x['DATE OCC']).dt.day\n",
    "new_x['Season'] = new_x['Month'].apply(get_season)\n",
    "\n",
    "\n",
    "\n",
    "# Clean df of nah, Vict Sex =X , and age = 0 and reset index\n",
    "new_x.dropna(inplace=True, subset= ['Vict Age','Vict Sex','Vict Descent'])\n",
    "new_x = new_x[new_x['Vict Sex'] != 'X'].reset_index(drop=True)\n",
    "new_x = new_x[new_x['Vict Descent'] != 'X'].reset_index(drop=True)\n",
    "new_x = new_x[new_x['Vict Age'] !=  0].reset_index(drop=True)\n",
    "\n",
    "#Add categorical features as 1 or 0 for seasons\n",
    "new_x['Spring'] = np.where((new_x['Season'] == 'Spring'), 1,0)\n",
    "new_x['Summer'] = np.where((new_x['Season'] == 'Summer'), 1,0)\n",
    "new_x['Fall'] = np.where((new_x['Season'] == 'Fall'), 1,0)\n",
    "new_x['Winter'] = np.where((new_x['Season'] == 'Winter'), 1,0)\n",
    "\n",
    "# #Add categorical featrues as 1 or 0 for Vict Sex\n",
    "# new_x['Male'] = np.where((new_x['Vict Sex'] == 'M'), 1,0)\n",
    "# new_x['Female'] = np.where((new_x['Vict Sex'] == 'F'), 1,0)\n",
    "\n",
    "# #Add categorical features as 1 or 0 for Vict Descent\n",
    "df_encoded = pd.get_dummies(new_x, columns= ['Vict Descent','Day_of_week','Crm Cd Desc','AREA','Crm Cd'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "feature_cols_list = list(df_encoded.columns.values)\n",
    "\n",
    "remove_cols = [\n",
    "    'DATE OCC',\n",
    "    'Vict Sex',\n",
    "    'Month',\n",
    "    'Season',\n",
    "    'Crm Cd Desc',\n",
    "    'Male',\n",
    "    'Female',\n",
    "    'LOCATION',\n",
    "    'AREA',\n",
    "    'Crm cd'\n",
    "    ]\n",
    "\n",
    "\n",
    "feature_cols = list(set(feature_cols_list).difference(remove_cols))\n",
    "\n",
    "\n",
    "\n",
    "# use the above list to select the features from the original DataFrame\n",
    "X = df_encoded[feature_cols]\n",
    "# select a Series of labels (the last column) from the DataFrame\n",
    "y = df_encoded['Vict Sex'] # this is the original categorical labels (the latest revision of sklearn accepts non-numerical labels)\n",
    "\n",
    "\n",
    "for col in X.columns:\n",
    "    print(col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.Split the dataset into testing and training sets with the following parameters: test_size=0.4, random_state=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(438, 183)\n",
      "(293, 183)\n",
      "(438,)\n",
      "(293,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=10)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### F. Now, normalize (scale) the features. To normalize the data, you can simply use StandardScaler  from sklearn. (note: don’t normalize the target!). Remember that we can only use the statistics of X_train for normalization, and then apply it on both X_train and X_test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E.Instantiate a KNN object with K= 59, train it on the training set and test it on the testing set. Then, calculate the accuracy of your prediction as you learned in Lab3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6006825938566553\n"
     ]
    }
   ],
   "source": [
    "\n",
    "k = 59\n",
    "\n",
    "my_knn_for_cs4661 = KNeighborsClassifier(n_neighbors=k, weights='uniform') # name of the object is arbitrary!\n",
    "my_knn_for_cs4661.fit(X.values, y)\n",
    "\n",
    "\n",
    "### Training ONLY on the training set:\n",
    "# Training ONLY on the training set:\n",
    "\n",
    "my_knn_for_cs4661.fit(X_train_normalized, y_train)\n",
    "\n",
    "### Testing on the testing set:\n",
    "# Testing on the testing set:\n",
    "\n",
    "y_predict = my_knn_for_cs4661.predict(X_test_normalized)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F.Repeat part (E) for 1 to 60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5392491467576792, 0.5221843003412969, 0.5563139931740614, 0.5460750853242321, 0.5699658703071673, 0.5426621160409556, 0.552901023890785, 0.5358361774744027, 0.5665529010238908, 0.5494880546075085, 0.5597269624573379, 0.5733788395904437, 0.5699658703071673, 0.590443686006826, 0.552901023890785, 0.5597269624573379, 0.5631399317406144, 0.5631399317406144, 0.5665529010238908, 0.5665529010238908, 0.552901023890785, 0.5426621160409556, 0.5665529010238908, 0.5665529010238908, 0.5631399317406144, 0.5733788395904437, 0.552901023890785, 0.5631399317406144, 0.5563139931740614, 0.5938566552901023, 0.5597269624573379, 0.5767918088737202, 0.5802047781569966, 0.5836177474402731, 0.5836177474402731, 0.590443686006826, 0.5870307167235495, 0.5631399317406144, 0.5767918088737202, 0.5699658703071673, 0.5631399317406144, 0.5733788395904437, 0.5733788395904437, 0.5631399317406144, 0.5665529010238908, 0.5597269624573379, 0.5767918088737202, 0.5631399317406144, 0.5733788395904437, 0.5631399317406144, 0.5665529010238908, 0.5733788395904437, 0.5631399317406144, 0.5836177474402731, 0.5836177474402731, 0.5836177474402731, 0.5870307167235495, 0.5972696245733788, 0.6006825938566553]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#K_values = [1,3,5,11,15,27,59]\n",
    "\n",
    "K_values = list(range(1,60))\n",
    "result_list = []\n",
    "\n",
    "for K in K_values:\n",
    "\n",
    "    my_knn_for_cs4661 = KNeighborsClassifier(n_neighbors=K, weights='uniform') # name of the object is arbitrary!\n",
    "    my_knn_for_cs4661.fit(X.values, y)\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=10) # We can fix the random_state for reproducibility!\n",
    "\n",
    "### Training ONLY on the training set:\n",
    "# Training ONLY on the training set:\n",
    "\n",
    "    X_train_normalized = scaler.fit_transform(X_train)\n",
    "    X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "    my_knn_for_cs4661.fit(X_train_normalized, y_train)\n",
    "\n",
    "### Testing on the testing set:\n",
    "# Testing on the testing set:\n",
    "\n",
    "    y_predict = my_knn_for_cs4661.predict(X_test_normalized)\n",
    "\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_predict)\n",
    "    result_list.append(accuracy)\n",
    "print(result_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The best K value is 59"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
